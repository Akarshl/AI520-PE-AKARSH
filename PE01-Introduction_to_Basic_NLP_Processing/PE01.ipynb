{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ab52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71d9497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa7cee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text sentiment\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...  negative\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...  negative\n",
       "2  If only to avoid making this type of film in t...  negative\n",
       "3  This film was probably inspired by Godard's Ma...  negative\n",
       "4  Oh, brother...after hearing about this ridicul...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load IMDb dataset, train split\n",
    "imdb_dataset = load_dataset('imdb', split='train')\n",
    "\n",
    "# Create new dataframe with 'review_text' and 'sentiment' columns\n",
    "df = pd.DataFrame({\n",
    "    'review_text': imdb_dataset['text'],\n",
    "    'sentiment': imdb_dataset['label']\n",
    "})\n",
    "\n",
    "# Map sentiment labels (0->'negative', 1->'positive')\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "df['sentiment'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# Save processed dataset as CSV\n",
    "df.to_csv('movie_reviews.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display sample rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02af15f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>film probably inspired godards masculin fémini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godard's Ma...   \n",
       "4  Oh, brother...after hearing about this ridicul...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  rented curiousyellow video store controversy s...  \n",
       "1  curious yellow risible pretentious steaming pi...  \n",
       "2  avoid making type film future film interesting...  \n",
       "3  film probably inspired godards masculin fémini...  \n",
       "4  oh brotherafter hearing ridiculous film umptee...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to lowercase\n",
    "df['processed_text'] = df['review_text'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df['processed_text'] = df['processed_text'].apply(lambda x: x.translate(translator))\n",
    "\n",
    "# Remove stopwords using NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['processed_text'] = df['processed_text'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "df[['review_text', 'processed_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ba809",
   "metadata": {},
   "source": [
    "Text Preprocessing\n",
    "\n",
    "What is the purpose of text preprocessing in NLP applications?\n",
    "\n",
    "To clean and standardize text data, reducing noise and variability so models can better understand and analyze the content.\n",
    "\n",
    "How does stop word removal affect text analysis?\n",
    "\n",
    "It removes common words that often don't carry significant meaning, which helps to focus on important keywords and reduces dimensionality.\n",
    "\n",
    "Why is case normalization important in text preprocessing?\n",
    "\n",
    "To ensure words are treated uniformly regardless of capitalization (e.g., \"The\" and \"the\" are treated as the same word).\n",
    "\n",
    "What are potential drawbacks of removing stop words?\n",
    "\n",
    "Sometimes stop words can carry important contextual or semantic meaning, so removing them may lose nuance or change meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904f6286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>[I rented I AM CURIOUS-YELLOW from my video st...</td>\n",
       "      <td>[I, rented, I, AM, CURIOUS-YELLOW, from, my, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>[\"I Am Curious: Yellow\" is a risible and prete...</td>\n",
       "      <td>[``, I, Am, Curious, :, Yellow, '', is, a, ris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>[If only to avoid making this type of film in ...</td>\n",
       "      <td>[If, only, to, avoid, making, this, type, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>[This film was probably inspired by Godard's M...</td>\n",
       "      <td>[This, film, was, probably, inspired, by, Goda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>[Oh, brother...after hearing about this ridicu...</td>\n",
       "      <td>[Oh, ,, brother, ..., after, hearing, about, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godard's Ma...   \n",
       "4  Oh, brother...after hearing about this ridicul...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [I rented I AM CURIOUS-YELLOW from my video st...   \n",
       "1  [\"I Am Curious: Yellow\" is a risible and prete...   \n",
       "2  [If only to avoid making this type of film in ...   \n",
       "3  [This film was probably inspired by Godard's M...   \n",
       "4  [Oh, brother...after hearing about this ridicu...   \n",
       "\n",
       "                                         word_tokens  \n",
       "0  [I, rented, I, AM, CURIOUS-YELLOW, from, my, v...  \n",
       "1  [``, I, Am, Curious, :, Yellow, '', is, a, ris...  \n",
       "2  [If, only, to, avoid, making, this, type, of, ...  \n",
       "3  [This, film, was, probably, inspired, by, Goda...  \n",
       "4  [Oh, ,, brother, ..., after, hearing, about, t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Tokenization\n",
    "import pandas as pd\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Sample training text for tokenizer\n",
    "sample_train_text = \"\"\"\n",
    "This is a movie review. It has multiple sentences. Some reviews are long. Others are short.\n",
    "This example is used to train a basic PunktSentenceTokenizer.\n",
    "\"\"\"\n",
    "\n",
    "#Train a sentence tokenizer manually\n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(sample_train_text)\n",
    "\n",
    "sentence_tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
    "\n",
    "#Use TreebankWordTokenizer\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "#Apply tokenization to your dataframe\n",
    "df = pd.read_csv(\"movie_reviews.csv\")\n",
    "\n",
    "# Apply sentence and word tokenization\n",
    "df['sentences'] = df['review_text'].apply(lambda x: sentence_tokenizer.tokenize(str(x)))\n",
    "df['word_tokens'] = df['review_text'].apply(lambda x: word_tokenizer.tokenize(str(x)))\n",
    "\n",
    "df[['review_text', 'sentences', 'word_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db679d34",
   "metadata": {},
   "source": [
    "Text Tokenization\n",
    "\n",
    "What is the difference between word and sentence tokenization?\n",
    "\n",
    "Sentence tokenization splits text into sentences, while word tokenization splits sentences into individual words or tokens.\n",
    "\n",
    "Why is tokenization important for text analysis?\n",
    "\n",
    "Tokenization breaks down raw text into manageable units for processing, enabling analysis at word or sentence level.\n",
    "\n",
    "How do regular expressions help in tokenization?\n",
    "\n",
    "They allow defining flexible patterns to identify tokens, such as words, numbers, or punctuation.\n",
    "\n",
    "What challenges might you encounter when tokenizing social media text?\n",
    "\n",
    "Informal language, emojis, hashtags, slang, and misspellings can confuse tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6590057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>i rented i am curiousyellow from my video stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>i am curious yellow risible pretentious steami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>only avoid making type film future film intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>film probably inspired godards masculin fémini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>oh brotherafter hearing about ridiculous film ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godard's Ma...   \n",
       "4  Oh, brother...after hearing about this ridicul...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  i rented i am curiousyellow from my video stor...  \n",
       "1  i am curious yellow risible pretentious steami...  \n",
       "2  only avoid making type film future film intere...  \n",
       "3  film probably inspired godards masculin fémini...  \n",
       "4  oh brotherafter hearing about ridiculous film ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "minimal_stopwords = set([\n",
    "    \"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\", \"while\", \"this\", \"is\", \"of\", \"in\", \n",
    "    \"to\", \"with\", \"on\", \"for\", \"as\", \"by\", \"it\", \"was\", \"that\", \"are\", \"be\"\n",
    "])\n",
    "\n",
    "# Load CSV from previous task\n",
    "df = pd.read_csv(\"movie_reviews.csv\")\n",
    "\n",
    "#Convert to lowercase\n",
    "df['processed_text'] = df['review_text'].str.lower()\n",
    "\n",
    "#Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df['processed_text'] = df['processed_text'].apply(lambda x: x.translate(translator))\n",
    "\n",
    "#Remove stopwords (using fallback list above)\n",
    "df['processed_text'] = df['processed_text'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in minimal_stopwords])\n",
    ")\n",
    "\n",
    "df[['review_text', 'processed_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ef9c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Frequent Words:\n",
      "br: 57145\n",
      "movie: 41813\n",
      "film: 37461\n",
      "not: 30193\n",
      "you: 29509\n",
      "his: 29252\n",
      "have: 27667\n",
      "he: 26655\n",
      "one: 25511\n",
      "its: 25055\n",
      "at: 23364\n",
      "all: 23161\n",
      "they: 20961\n",
      "from: 20392\n",
      "who: 20375\n",
      "so: 19894\n",
      "like: 19645\n",
      "her: 18138\n",
      "just: 17632\n",
      "about: 17241\n"
     ]
    }
   ],
   "source": [
    "# Bag-of-words with top 1000 features on processed text\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "bow_matrix = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_freq = np.asarray(bow_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "# Top 20 most frequent words\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "word_freq_dict = dict(zip(vocab, word_freq))\n",
    "top_20_words = sorted(word_freq_dict.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "print(\"Top 20 Most Frequent Words:\")\n",
    "for word, freq in top_20_words:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116eccf",
   "metadata": {},
   "source": [
    "Text Vectorization Questions\n",
    "\n",
    "What information does a bag-of-words model capture?\n",
    "\n",
    "It captures word frequency counts without considering word order or grammar.\n",
    "\n",
    "How does vectorization help in text analysis?\n",
    "\n",
    "It converts text into numerical features suitable for machine learning models.\n",
    "\n",
    "What are the limitations of basic frequency counts?\n",
    "\n",
    "They ignore context, word order, and semantics; rare but important words might be undervalued.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d673f956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>[I rented I AM CURIOUS-YELLOW from my video st...</td>\n",
       "      <td>[I, rented, I, AM, CURIOUS-YELLOW, from, my, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>[\"I Am Curious: Yellow\" is a risible and prete...</td>\n",
       "      <td>[``, I, Am, Curious, :, Yellow, '', is, a, ris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>[If only to avoid making this type of film in ...</td>\n",
       "      <td>[If, only, to, avoid, making, this, type, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>[This film was probably inspired by Godard's M...</td>\n",
       "      <td>[This, film, was, probably, inspired, by, Goda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>[Oh, brother...after hearing about this ridicu...</td>\n",
       "      <td>[Oh, ,, brother, ..., after, hearing, about, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godard's Ma...   \n",
       "4  Oh, brother...after hearing about this ridicul...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [I rented I AM CURIOUS-YELLOW from my video st...   \n",
       "1  [\"I Am Curious: Yellow\" is a risible and prete...   \n",
       "2  [If only to avoid making this type of film in ...   \n",
       "3  [This film was probably inspired by Godard's M...   \n",
       "4  [Oh, brother...after hearing about this ridicu...   \n",
       "\n",
       "                                         word_tokens  \n",
       "0  [I, rented, I, AM, CURIOUS-YELLOW, from, my, v...  \n",
       "1  [``, I, Am, Curious, :, Yellow, '', is, a, ris...  \n",
       "2  [If, only, to, avoid, making, this, type, of, ...  \n",
       "3  [This, film, was, probably, inspired, by, Goda...  \n",
       "4  [Oh, ,, brother, ..., after, hearing, about, t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "#Train a simple Punkt tokenizer\n",
    "sample_train_text = \"\"\"\n",
    "This is a sentence. That is another one. Reviews can be long or short. Some have lots of punctuation!\n",
    "\"\"\"\n",
    "\n",
    "trainer = PunktTrainer()\n",
    "trainer.train(sample_train_text)\n",
    "sentence_tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
    "\n",
    "#Use Treebank tokenizer for word tokenization\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "#Tokenize reviews\n",
    "df['sentences'] = df['review_text'].apply(lambda x: sentence_tokenizer.tokenize(str(x)))\n",
    "df['word_tokens'] = df['review_text'].apply(lambda x: word_tokenizer.tokenize(str(x)))\n",
    "\n",
    "df[['review_text', 'sentences', 'word_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f440c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences per review: 10.92\n",
      "Average number of words before preprocessing: 273.90\n",
      "Average number of words after preprocessing: 162.56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words_before</th>\n",
       "      <th>num_words_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>i rented i am curiousyellow from my video stor...</td>\n",
       "      <td>10</td>\n",
       "      <td>327</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>i am curious yellow risible pretentious steami...</td>\n",
       "      <td>11</td>\n",
       "      <td>244</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>only avoid making type film future film intere...</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>film probably inspired godards masculin fémini...</td>\n",
       "      <td>7</td>\n",
       "      <td>151</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>oh brotherafter hearing about ridiculous film ...</td>\n",
       "      <td>7</td>\n",
       "      <td>414</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godard's Ma...   \n",
       "4  Oh, brother...after hearing about this ridicul...   \n",
       "\n",
       "                                      processed_text  num_sentences  \\\n",
       "0  i rented i am curiousyellow from my video stor...             10   \n",
       "1  i am curious yellow risible pretentious steami...             11   \n",
       "2  only avoid making type film future film intere...              3   \n",
       "3  film probably inspired godards masculin fémini...              7   \n",
       "4  oh brotherafter hearing about ridiculous film ...              7   \n",
       "\n",
       "   num_words_before  num_words_after  \n",
       "0               327              205  \n",
       "1               244              149  \n",
       "2               119               66  \n",
       "3               151               81  \n",
       "4               414              219  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison DataFrame\n",
    "df['num_sentences'] = df['sentences'].apply(len)\n",
    "df['num_words_before'] = df['word_tokens'].apply(len)\n",
    "df['num_words_after'] = df['processed_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "comparison_df = df[['review_text', 'processed_text', 'num_sentences', 'num_words_before', 'num_words_after']]\n",
    "\n",
    "# Calculate statistics\n",
    "avg_sentences = comparison_df['num_sentences'].mean()\n",
    "avg_words_before = comparison_df['num_words_before'].mean()\n",
    "avg_words_after = comparison_df['num_words_after'].mean()\n",
    "\n",
    "print(f\"Average number of sentences per review: {avg_sentences:.2f}\")\n",
    "print(f\"Average number of words before preprocessing: {avg_words_before:.2f}\")\n",
    "print(f\"Average number of words after preprocessing: {avg_words_after:.2f}\")\n",
    "\n",
    "# Save processed data\n",
    "comparison_df.to_csv('processed_reviews_comparison.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Save BoW representation as DataFrame and CSV\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vocab)\n",
    "bow_df.to_csv('bow_representation.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Display sample comparisons\n",
    "comparison_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d1736",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "This code covers loading the IMDb dataset, preprocessing text (lowercasing, punctuation removal, stopwords removal), tokenizing sentences and words, vectorizing text using bag-of-words, analyzing word frequencies, and saving detailed comparison data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
